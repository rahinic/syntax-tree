{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1><div align=\"center\"> Penn Treebank Dataset Syntax Tree Parser </div></h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Necessary Package Imports "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Package imports\r\n",
    "from typing import Dict, List\r\n",
    "from nltk.tree import Tree\r\n",
    "import logging\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Sentence String to Syntax Tree Conversion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sentence = \"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\"\r\n",
    "t = Tree.fromstring(sentence)\r\n",
    "print(t)\r\n",
    "t.height()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# this is my example sentence:\r\n",
    "sentence = \"(TOP (S (NP (NNP Ms.) (NNP Haag)) (VP (VBZ plays) (NP (NNP Elianti))) (. .)))\"\r\n",
    "# using nltk library to parse this string to tree:\r\n",
    "parse_tree = Tree.fromstring(sentence)\r\n",
    "print(parse_tree)\r\n",
    "print(parse_tree.height())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TOP\n",
      "  (S\n",
      "    (NP (NNP Ms.) (NNP Haag))\n",
      "    (VP (VBZ plays) (NP (NNP Elianti)))\n",
      "    (. .)))\n",
      "6\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def build_parse_dict(src_tree: Tree) -> Dict:\r\n",
    "    \"\"\"\r\n",
    "    Build a multi-lvel dict of treebank data, adding target tags for each level from tags of higher level\r\n",
    "    \"\"\"\r\n",
    "    max_height = src_tree.height()\r\n",
    "    parse_dict = {\r\n",
    "        level: {\"tokens\": list(), \"tags\": list(), \"targets\": list()}\r\n",
    "        for level in range(2, max_height)\r\n",
    "    }\r\n",
    "    # top most level is redudant..so we can stop 1 level before\r\n",
    "    for level in range(2, max_height):\r\n",
    "        for subtree in src_tree.subtrees(lambda t: t.height() == level):\r\n",
    "            parse_dict[level][\"tokens\"].append(subtree.leaves())\r\n",
    "            parse_dict[level][\"tags\"].append(subtree.label())\r\n",
    "\r\n",
    "    # each level might be missing some unary tokens, add them back to 'tokens'\r\n",
    "    # for completeness\r\n",
    "    # parse_dict = add_missing_tokens(parse_dict)\r\n",
    "\r\n",
    "    # fill the tragets list of each level based on tags of next level\r\n",
    "    # parse_dict = fill_targets(parse_dict, max_level=src_tree.height() - 1)\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{2: {'tokens': [['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now'], [','], ['would'], [\"n't\"], ['that'], ['be'], ['a'], ['novelty'], ['.']], 'tags': ['TOP', 'TOP', 'TOP', 'TOP', 'TOP', 'TOP', 'TOP', 'TOP', 'TOP', 'RB', ',', 'MD', 'RB', 'VB', 'VB', 'DT', 'NN', '.'], 'targets': []}, 3: {'tokens': [['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now'], ['that'], ['a', 'novelty']], 'tags': ['TOP', 'TOP', 'TOP', 'INTJ', 'NP', 'NP'], 'targets': []}, 4: {'tokens': [['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['be', 'a', 'novelty']], 'tags': ['TOP', 'VP'], 'targets': []}, 5: {'tokens': [['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.'], ['Now', ',', 'would', \"n't\", 'that', 'be', 'a', 'novelty', '.']], 'tags': ['TOP', 'SQ'], 'targets': []}}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "75c4db28bb58e6de10e05be21b6046b5ba21d9aba4af4007d97c2f3325bc0896"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}